{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from IPython.display import HTML, display_html\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f\"{FOLDER_PATH}train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0001ea8717f6de06  Thank you for understanding. I think very high...      0   \n",
       "1  000247e83dcc1211                   :Dear god this site is horrible.      0   \n",
       "2  0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...      0   \n",
       "3  0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...      0   \n",
       "4  00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f\"{FOLDER_PATH}test.csv\")\n",
    "test_labels = pd.read_csv(f\"{FOLDER_PATH}test_labels.csv\")\n",
    "\n",
    "test = pd.merge(test, test_labels[test_labels[\"toxic\"] != -1])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    }
   ],
   "source": [
    "pred_test = test.copy()\n",
    "\n",
    "class_labels = train.columns.tolist()[2:]\n",
    "print(f\"Labels: {class_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer()\n",
    "tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['stemmed_comment_text'] = train['comment_text'].apply(\n",
    "    lambda x: \" \".join([stemmer.stem(word) for word in tokenizer.tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 466 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test['stemmed_comment_text'] = test['comment_text'].apply(\n",
    "    lambda x: \" \".join([stemmer.stem(word) for word in tokenizer.tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(min_df=2, max_df=0.9, strip_accents='unicode', sublinear_tf=True,\n",
    "                                  stop_words='english', max_features=10000, token_pattern=r'\\w{1,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = word_vectorizer.fit_transform(train['stemmed_comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.05 s, sys: 75.6 ms, total: 4.13 s\n",
      "Wall time: 3.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_features = word_vectorizer.transform(test['stemmed_comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {}\n",
    "for label in class_labels:\n",
    "    y_true = train[label]\n",
    "    model = LogisticRegression(C=1.0, solver='sag', random_state=42)\n",
    "    model.fit(train_features, y_true)\n",
    "    models_dict[label] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.8 ms, sys: 1.74 ms, total: 29.5 ms\n",
      "Wall time: 27.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for label in class_labels:\n",
    "    pred_test[label] = models_dict[label].predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.9765\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC-AUC = {roc_auc_score(test.values[:, 2:-1].astype(int), pred_test.values[:, 2:-1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL INTERPRETATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
    "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
    "              font_style=\"font-size:14px;\"):\n",
    "\n",
    "    def get_color_hex(weight):\n",
    "        rgba = cmap(1. / (1 + np.exp(weight)), bytes=True)\n",
    "        return '#%02X%02X%02X' % rgba[:3]\n",
    "    \n",
    "    tokens_html = [token_template.format(token=token, color_hex=get_color_hex(weight))\n",
    "                   for token, weight in tokens_and_weights]\n",
    "       \n",
    "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
    "    if display:\n",
    "        display_html(HTML(raw_html))\n",
    "        \n",
    "    return raw_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: toxic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #A2A2FF\">mel</span> <span style=\"background-color: #EAEAFF\">gibson</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #0404FF\">nazi</span> <span style=\"background-color: #0000FF\">bitch</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #D2D2FF\">make</span> <span style=\"background-color: #1212FF\">shitti</span> <span style=\"background-color: #FF6060\">movi</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">he</span> <span style=\"background-color: #FFFEFE\">has</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFFEFE\">much</span> <span style=\"background-color: #FFFEFE\">buttsex</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">his</span> <span style=\"background-color: #0000FF\">asshol</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">now</span> <span style=\"background-color: #6868FF\">big</span> <span style=\"background-color: #FFFEFE\">enough</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FF4848\">consid</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #D6D6FF\">countri</span> <span style=\"background-color: #FFFEFE\">.</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: severe_toxic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #FFF8F8\">mel</span> <span style=\"background-color: #FCFCFF\">gibson</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #2828FF\">nazi</span> <span style=\"background-color: #0C0CFF\">bitch</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #FFC2C2\">make</span> <span style=\"background-color: #7676FF\">shitti</span> <span style=\"background-color: #FFB8B8\">movi</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">he</span> <span style=\"background-color: #FFFEFE\">has</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFFEFE\">much</span> <span style=\"background-color: #FFFEFE\">buttsex</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">his</span> <span style=\"background-color: #0A0AFF\">asshol</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">now</span> <span style=\"background-color: #5C5CFF\">big</span> <span style=\"background-color: #FFFEFE\">enough</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFB6B6\">consid</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #EAEAFF\">countri</span> <span style=\"background-color: #FFFEFE\">.</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: obscene\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #F2F2FF\">mel</span> <span style=\"background-color: #EAEAFF\">gibson</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #5050FF\">nazi</span> <span style=\"background-color: #0000FF\">bitch</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #C6C6FF\">make</span> <span style=\"background-color: #2828FF\">shitti</span> <span style=\"background-color: #FFBABA\">movi</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">he</span> <span style=\"background-color: #FFFEFE\">has</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFFEFE\">much</span> <span style=\"background-color: #FFFEFE\">buttsex</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">his</span> <span style=\"background-color: #0000FF\">asshol</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">now</span> <span style=\"background-color: #4E4EFF\">big</span> <span style=\"background-color: #FFFEFE\">enough</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FF8383\">consid</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFF2F2\">countri</span> <span style=\"background-color: #FFFEFE\">.</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: threat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #FFFAFA\">mel</span> <span style=\"background-color: #FFFCFC\">gibson</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #8080FF\">nazi</span> <span style=\"background-color: #8383FF\">bitch</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #FFBEBE\">make</span> <span style=\"background-color: #B6B6FF\">shitti</span> <span style=\"background-color: #F6F6FF\">movi</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">he</span> <span style=\"background-color: #FFFEFE\">has</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFFEFE\">much</span> <span style=\"background-color: #FFFEFE\">buttsex</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">his</span> <span style=\"background-color: #9090FF\">asshol</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">now</span> <span style=\"background-color: #DCDCFF\">big</span> <span style=\"background-color: #FFFEFE\">enough</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFC0C0\">consid</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFDADA\">countri</span> <span style=\"background-color: #FFFEFE\">.</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: insult\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #DCDCFF\">mel</span> <span style=\"background-color: #FFFEFE\">gibson</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #1212FF\">nazi</span> <span style=\"background-color: #0000FF\">bitch</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #D0D0FF\">make</span> <span style=\"background-color: #5454FF\">shitti</span> <span style=\"background-color: #FFA3A3\">movi</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">he</span> <span style=\"background-color: #FFFEFE\">has</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFFEFE\">much</span> <span style=\"background-color: #FFFEFE\">buttsex</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">his</span> <span style=\"background-color: #0000FF\">asshol</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">now</span> <span style=\"background-color: #D6D6FF\">big</span> <span style=\"background-color: #FFFEFE\">enough</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FF9292\">consid</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #F6F6FF\">countri</span> <span style=\"background-color: #FFFEFE\">.</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: identity_hate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #FFEAEA\">mel</span> <span style=\"background-color: #FFF2F2\">gibson</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #0202FF\">nazi</span> <span style=\"background-color: #3A3AFF\">bitch</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #EAEAFF\">make</span> <span style=\"background-color: #CACAFF\">shitti</span> <span style=\"background-color: #C8C8FF\">movi</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">he</span> <span style=\"background-color: #FFFEFE\">has</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFFEFE\">much</span> <span style=\"background-color: #FFFEFE\">buttsex</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">his</span> <span style=\"background-color: #AAAAFF\">asshol</span> <span style=\"background-color: #FFFEFE\">is</span> <span style=\"background-color: #FFFEFE\">now</span> <span style=\"background-color: #C2C2FF\">big</span> <span style=\"background-color: #FFFEFE\">enough</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FF7070\">consid</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #5454FF\">countri</span> <span style=\"background-color: #FFFEFE\">.</span></p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example = test[\"stemmed_comment_text\"][63976]\n",
    "\n",
    "for label, model in models_dict.items():\n",
    "    tokens_and_weights = []\n",
    "    for word in example.split():\n",
    "        index = word_vectorizer.vocabulary_.get(word)\n",
    "        tokens_and_weights.append([word, model.coef_[0][index] if index else 0])\n",
    "    print(f\"Label: {label}\")\n",
    "    draw_html([(tok, weight) for tok, weight in tokens_and_weights], font_style='font-size:20px;');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главной целью задания было построить очень маленькую и очень быструю модель. Однако никаких конкретных ограничений на точность работы, время работы и размер модели даны не были. Такая поставка задачи допускает введения собственных уточнений целей задания.\n",
    "\n",
    "Изучив задание и данные, я поставил себе цель, сделать максимально быструю модель, при этом потеряв в качестве работы не более ~1% относительно модели, занимающей 1-ое место на лидерборде.\n",
    "\n",
    "Обычно, первая модель, которую хочется попробовать в задачах классификации с числовыми данными - это логистическая регрессия. При правильном выделении признаков из текстов оказалось, что обычная логистическая регрессия прекрасно справляется с поставленной задачей.\n",
    "\n",
    "Самые известные способы выделения признаков из текстов, это применение различных счётчиков (CountVectorizer, TfidfVectorizer) и использование эмбендингов (Word2Vec, GloVe, FastText). Однако матрицы эмбендингов занимают довольно много места. Например, предобученные эмбендинги из библиотеки gensim занимают около 300-1000мб в зависимости от корпуса текстов, на котором они были обучены, и размера полученных векторов. Поэтому я решил отказаться от использования эмбендингов для построения максимально легкой модели.\n",
    "\n",
    "Практически во всех случаях TfidfVectorizer работает лучше, чем CountVectorizer. Данная задача оказалась не исключением.\n",
    "\n",
    "Для построения максимально быстрой модели, я решил отказаться от использования каких-либо нейронных сетей. Однако очевидно, что для этой задачи прекрасно бы подошли какие-нибудь сети на основе LSTM, GRU, CNN и их различных комбинаций и модификаций. Но также очевидно, что любая такая сеть работала бы значительно дольше, чем Logistic Regression, но при этом, судя по LB соревнования, не одна бы из таких глубоких сеток не смогла бы превысить скор логистической регрессии более чем на ~1%. Победители соревнования используют стэкинг большого числа различных нейросеток и кучу различных эмбендингов, из-за чего их модель является крайне медленной и громоздкой.\n",
    "\n",
    "В данном ноутбуке я оставил 3 модели логистической регрессии, обученные на немного отличающихся признаках. Модели отличаются качеством и скоростью работы. Я не могу выделить одну из них как лучшую, потому что всё зависит от предпочтений между скоростью и точностью работы.\n",
    "\n",
    "* Модель, обученную на признаках из TF-IDF, посчитанных на текстах, к словам которых была применена операция стемминга (лемматизация работает хуже) представлена выше. Её скор ~0.9765, что всего на 1.2% ниже, чем у победителей соревнования(0.9885). При этом одно предсказание у модели занимает ~0.43ms на преобработанных данных и ~1.49ms на сырых данных.\n",
    "\n",
    "* В дополнении №1 представлена модель, обученная на признаках из TF-IDF, посчитанных на сырых текстах. Её скор ~0.9664, что уже на 2.2% ниже, чем у победителей соревнования. Зато одно предсказание у модели занимает ~0.35ms на преобработанных данных и ~0.41ms на сырых данных.\n",
    "\n",
    "* В дополнении №2 представлена модель, обученная на признаках из TF-IDF, посчитанных не только по словам, но и по символам. Считать TF-IDF по символам в данной задаче имеет смысл, так как, например, в текстах часто встречаются типичные для токсичных сообщений символы. Скор этой модели ~0.98, что всего лишь на 0.8% ниже, чем у победителей соревнования. Одно предсказание у модели занимает ~0.25ms на преобработанных данных и ~2.41ms на сырых данных.\n",
    "\n",
    "1) Какая получилась точность у модели? __Лучшая точность у модели получилась: ~0.98 roc-auc__\n",
    "\n",
    "Следующие вопросы более актуальны для более сложных моделей, например, нейронных сетей, но кое-что можно сделать и для логистической регрессии.\n",
    "\n",
    "2) Какие есть способы ускорения/уменьшения модели? __Ускорить модель можно с помощью распараллеливания процесса подсчёта TF-IDF и вычисления самой логистической регрессии. Так как размер логистической регрессии пропорционален количеству признаков, то уменьшить её размер можно с помощью уменьшения количества признаков, например, с помощью различных методов понижения размерности таких как: PCA, SVD и тд.__\n",
    "\n",
    "3) Как выбрать баланс между качеством и скоростью? __Выбор баланса между скоростью и качеством напрямую зависит от конкретной задачи. То есть от того, где будет применяться данная модель. Например, если нужно делать предсказания онлайн и с телефона, то нужно отдать предпочтение скорости, а если нужно предсказывать с компьютера, то качеству.__\n",
    "\n",
    "4) Что лучше — тяжелая модель и потом ее оптимизировать или сразу легкая? Поясните почему. __Лучше использовать сразу легкую модель. У многих моделей есть так называемое \"bottleneck\", которое очень сложно оптимизировать и которое способствует наибольшему замедлению скорости работы модели. Так же заранее никогда не известно насколько сложной должна быть модель, чтобы справиться с поставленной задачей. Например, если в данной задаче сразу броситься писать глубокую нейросетку, можно так и не узнать, что это оверхед и простой логистическая регресии будет достаточно. Также для сложных моделей, имеющих множество зависимых друг от друга параметров, совсем не очевидно как правильно их оптимизировать. Например, для сверточных нейросетей на ICML 2019 вышла крутая статья (https://arxiv.org/abs/1905.11946), авторы которой показали, что предыдущие методы оптимизации сверточных нейросетей были неоптимальными из-за нетривиальной зависимости между глубиной, числом каналов и разрешением свертоных нейросетей (также они нашли эту зависимость).__\n",
    "\n",
    "5) Опишите ваш подход. Чем он лучше других возможных подходов? Какие у него могут быть недостатки? __Мой подход является традиционным для любых задач машинного обучения - нужно начинать с простого и двигаться к сложному. Очевидным преимуществом такого подхода является большая вероятность найти простое, но эффективное решение. Очевидным недостатком явлется возможность потратить много времени впустую. Например, мне повезло и самое простое решение оказалось подходящим, но в то же время могло случиться так, что только глубокая нейронная сеть подошла бы для данной задачи. В таком случае я потратил бы много времени на поиски не существующего простого решения, хотя мог бы сразу броситься писать нейросеть.__\n",
    "\n",
    "6) Что можно сделать, чтобы улучшить классификатор? __Сложно, конечно, улучшить классификатор, полностью построенный на логистической регрессии. Но всё же есть 3 пути, чтобы сделать это:__\n",
    "* __Более тчательный подбор гиперпараметров логистической регрессии. Так как в моделе используется шесть независимых классификаторов, то и гиперпараметры можно подбирать для каждого классификатора отдельно.__\n",
    "* __Выделение дополнительных качественных признаков из текстов. Если нельзя увеличить время предобработки данных, то можно попробовать более качественно подобрать гиперпараметры TfidfVectorizer и/или более качественно почистить сами тексты. Если же можно увеличивать время работы/размер модели, то можно выделить признаки с помощью разных методов, например, с помощью эмбендингов и объединить полученные признаки.__\n",
    "* __Можно попробовать учесть зависимость между классами текстов. При изучении данных видно, что многие классы являются зависимыми. Например, если текст содержит угрозу, то, скорее всего, он также является токсичным. Учесть такую зависимость можно, например, добавляя ответы одного из классификаторов в качестве признаков для другого.__\n",
    "\n",
    "Выбрав линейную модель в качестве классификатора, интерпретируемость появляется автоматически :) Веса линейной модели являются мерой значимости соответствующих им признаков. Модуль веса определяет значимость признака, а знак указывает на класс, к которому данный признак \"оттягивает\" модель. В визуализации выше, синие слова имеют отрицательные веса и \"оттягивают\" модель к \"dirty\" классу, а красные слова имею положительные веса и \"оттягивают\" модель к \"clear\" классу.\n",
    "Вообще говоря, с помощью нехитрого трюка и визуализации выше можно добавить интерпретируемость в любую модель. Нехитрый трюк заключается в следующем: будем наблюдать как модель реагирует на входные возмущения и в зависимости от этих реакций, станет понятно, какое влияение имеет каждое слово. В качестве входных возмущений можно подавать на вход модели один и тот же текст, но каждый раз заменять одно из слов на \"UNK\", и смотреть как от этого меняется предсказание модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix №1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(min_df=2, max_df=0.9, strip_accents='unicode', sublinear_tf=True,\n",
    "                                  stop_words='english', max_features=10000, token_pattern=r'\\w{1,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = word_vectorizer.fit_transform(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.84 s, sys: 64.5 ms, total: 3.91 s\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_features = word_vectorizer.transform(test['stemmed_comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {}\n",
    "for label in class_labels:\n",
    "    y_true = train[label]\n",
    "    model = LogisticRegression(C=1.0, solver='sag', random_state=42)\n",
    "    model.fit(train_features, y_true)\n",
    "    models_dict[label] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.1 ms, sys: 1.4 ms, total: 24.5 ms\n",
      "Wall time: 22.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for label in class_labels:\n",
    "    pred_test[label] = models_dict[label].predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.9664\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC-AUC = {roc_auc_score(test.values[:, 2:-1].astype(int), pred_test.values[:, 2:-1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix №2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(min_df=2, max_df=0.9, strip_accents='unicode', sublinear_tf=True,\n",
    "                                  stop_words='english', max_features=20000, token_pattern=r'\\w{1,}')\n",
    "\n",
    "char_vectorizer = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', analyzer='char',\n",
    "                                  stop_words='english', ngram_range=(2, 5), max_features=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_train_features = word_vectorizer.fit_transform(train['stemmed_comment_text'])\n",
    "char_train_features = char_vectorizer.fit_transform(train['comment_text'])\n",
    "train_features = sp.hstack([word_train_features, char_train_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 2.16 s, total: 1min 17s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_test_features = word_vectorizer.transform(test['stemmed_comment_text'])\n",
    "char_test_features = char_vectorizer.transform(test['comment_text'])\n",
    "test_features = sp.hstack([word_test_features, char_test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {}\n",
    "for label in class_labels:\n",
    "    y_true = train[label]\n",
    "    model = LogisticRegression(C=1.1, solver='sag', random_state=42)\n",
    "    model.fit(train_features, y_true)\n",
    "    models_dict[label] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 1.42 s, total: 16.7 s\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for label in class_labels:\n",
    "    pred_test[label] = models_dict[label].predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.9800\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC-AUC = {roc_auc_score(test.values[:, 2:-1].astype(int), pred_test.values[:, 2:-1]):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
